# 第六章：机器学习和神经网络 - 练习题

## 一、选择题（每题2分，共20分）

1. 监督学习的特点是：
   A. 没有标签数据
   B. 有输入-输出对的训练数据
   C. 只有输入数据
   D. 只有输出数据

2. 神经网络中，权重更新的基本原则是：
   A. 增加错误预测的权重
   B. 减少预测正确的权重
   C. 根据误差梯度调整权重
   D. 随机调整权重

3. 以下哪种不是常见的激活函数？
   A. Sigmoid函数
   B. ReLU函数
   C. Softmax函数
   D. 线性回归函数

4. 在机器学习中，过拟合的表现是：
   A. 训练集和测试集都表现好
   B. 训练集表现好，测试集表现差
   C. 训练集表现差，测试集表现好
   D. 训练集和测试集都表现差

5. 支持向量机（SVM）的核心思想是：
   A. 最小化样本距离
   B. 最大化分类间隔
   C. 减少计算复杂度
   D. 增加样本数量

6. 以下哪个算法属于无监督学习？
   A. 线性回归
   B. 决策树
   C. K均值聚类
   D. 朴素贝叶斯

7. 在神经网络中，反向传播算法的数学基础是：
   A. 链式法则
   B. 泰勒展开
   C. 拉格朗日乘数法
   D. 牛顿法

8. 神经网络中的Dropout技术主要用于：
   A. 加速训练
   B. 防止过拟合
   C. 增加准确率
   D. 减少参数

9. 支持向量机处理非线性问题的方法是：
   A. 增加数据量
   B. 使用核函数
   C. 减少特征数
   D. 增加迭代次数

10. 以下哪种学习方式是通过与环境交互获得奖励来学习的？
    A. 监督学习
    B. 无监督学习
    C. 强化学习
    D. 半监督学习

## 二、填空题（每空2分，共20分）

1. 机器学习的三种基本学习方式是________、________和________。

2. 神经网络的基本组成单元是________，它包含________、________和________。

3. 常见的激活函数有________、________、________等。

4. 在支持向量机中，________是距离分类超平面最近的样本点。

5. 机器学习中的偏差-方差权衡中，偏差高表示________，方差高表示________。

6. 神经网络的三个重要组成部分是________、________和________。

## 三、计算题（每题10分，共30分）

1. 某单层感知机有两个输入x1=1, x2=2，权重w1=0.5, w2=0.8，偏置b=0.2，使用阶跃函数（输出=1当加权和≥0，否则为0）。计算输出。

2. 对于一个简单的神经网络：输入层2个神经元，隐藏层2个神经元，输出层1个神经元。输入x=[1, 1]，输入到隐藏的权重矩阵W1=[[0.1, 0.2], [0.3, 0.4]]，偏置b1=[0.1, 0.1]，隐藏到输出的权重W2=[0.5, 0.6]，偏置b2=0.2。使用Sigmoid激活函数计算输出。

3. 已知SVM的分类超平面方程为w·x + b = 0，其中w=[2, -1]，b=-3。判断点x1=[1, 2]和x2=[3, 1]分别属于哪一类（+1类或-1类）。

## 四、简答题（每题10分，共20分）

1. 解释神经网络中梯度消失问题的成因及其解决方案。

2. 比较监督学习、无监督学习和强化学习的特点和应用场景。

## 五、应用题（每题10分，共10分）

1. 设计一个基于神经网络的图像分类系统，要求详细说明网络架构设计、训练过程、优化策略和评估方法。

---
# 第六章：机器学习和神经网络 - 详细答案

## 一、选择题答案

1. **答案：B**
   详解：监督学习使用带标签的训练数据，即输入-输出对。

2. **答案：C**
   详解：根据误差相对于权重的梯度来调整权重，使误差最小化。

3. **答案：D**
   详解：线性回归是算法不是激活函数。

4. **答案：B**
   详解：过拟合是指模型在训练集上表现很好但在测试集上表现差。

5. **答案：B**
   详解：SVM的核心思想是找到最大间隔的分类超平面。

6. **答案：C**
   详解：K均值聚类是无监督学习算法，不需要标签数据。

7. **答案：A**
   详解：反向传播使用链式法则计算梯度。

8. **答案：B**
   详解：Dropout随机失活神经元，防止模型过于依赖特定神经元。

9. **答案：B**
   详解：使用核函数可以将非线性问题映射到高维空间变为线性可分。

10. **答案：C**
    详解：强化学习通过与环境交互获得奖励信号进行学习。

## 二、填空题答案

1. **答案：** 监督学习、无监督学习、强化学习
    详解：机器学习的三种基本学习方式。

2. **答案：** 神经元、输入、激活函数、输出
    详解：神经网络基本单元的组成。

3. **答案：** Sigmoid、ReLU、Tanh
    详解：常见的激活函数。

4. **答案：** 支持向量
    详解：支持向量是距离分类面最近的点。

5. **答案：** 欠拟合、过拟合
    详解：偏差高导致欠拟合，方差高导致过拟合。

6. **答案：** 输入层、隐藏层、输出层
    详解：神经网络的基本结构。

## 三、计算题答案

### 1. 单层感知机计算

**答案：**
计算过程：
- 加权和 = w1×x1 + w2×x2 + b = 0.5×1 + 0.8×2 + 0.2 = 0.5 + 1.6 + 0.2 = 2.3
- 由于2.3 ≥ 0，使用阶跃函数输出为1

**答案：** 输出为1

**详解：** 感知机通过加权求和后与阈值比较进行分类。

### 2. 神经网络前向传播

**答案：**
计算过程：

*隐藏层计算：*
- h1_in = 1×0.1 + 1×0.2 + 0.1 = 0.4
- h2_in = 1×0.3 + 1×0.4 + 0.1 = 0.8

*隐藏层输出（Sigmoid）：*
- h1_out = 1/(1+e^(-0.4)) ≈ 0.599
- h2_out = 1/(1+e^(-0.8)) ≈ 0.690

*输出层计算：*
- output_in = 0.599×0.5 + 0.690×0.6 + 0.2 = 0.2995 + 0.414 + 0.2 = 0.9135
- final_output = 1/(1+e^(-0.9135)) ≈ 0.714

**答案：** 最终输出约为0.714

**详解：** 逐层计算，每层都使用激活函数。

### 3. SVM分类

**答案：**
对于超平面w·x + b = 0，即[2, -1]·[x1, x2] - 3 = 0，即2x1 - x2 - 3 = 0

分类规则：w·x + b > 0为+1类，w·x + b < 0为-1类

对x1=[1, 2]：2×1 - 1×2 - 3 = 2 - 2 - 3 = -3 < 0，属于-1类
对x2=[3, 1]：2×3 - 1×1 - 3 = 6 - 1 - 3 = 2 > 0，属于+1类

**答案：** x1属于-1类，x2属于+1类

**详解：** 根据点到超平面的距离符号进行分类。

## 四、简答题答案

### 1. 梯度消失问题成因及解决方案

**成因：**
1. **激活函数问题：** Sigmoid和Tanh函数在饱和区梯度接近0
2. **链式法则累积：** 反向传播中梯度通过链式法则相乘
3. **网络深度：** 深层网络中梯度经过多次相乘后接近0
4. **权重初始化：** 不合适的初始化会导致梯度消失

**数学表达：**
∂E/∂w_l = (∂E/∂a_L) × ∏(i=l to L-1) (∂a_i+1/∂a_i) × (∂a_l/∂w_l)

**解决方案：**
1. **激活函数：** 使用ReLU等梯度恒为1的激活函数
2. **权重初始化：** 使用Xavier/He初始化方法
3. **归一化：** 批归一化（Batch Normalization）和层归一化
4. **残差连接：** ResNet中的跳跃连接
5. **梯度裁剪：** 防止梯度爆炸/消失
6. **网络架构：** 使用LSTM/GRU等门控机制

**详解：** 梯度消失是深层网络训练的主要障碍，需要从网络结构和训练方法上综合解决。

### 2. 三种学习方式比较

**监督学习：**
- **特点：** 使用带标签的训练数据
- **目标：** 学习输入到输出的映射
- **算法：** 线性回归、逻辑回归、SVM、神经网络
- **应用场景：** 图像分类、语音识别、预测分析

**无监督学习：**
- **特点：** 使用无标签数据
- **目标：** 发现数据中的结构和模式
- **算法：** K均值聚类、主成分分析、关联规则
- **应用场景：** 客户分群、异常检测、数据压缩

**强化学习：**
- **特点：** 通过与环境交互获得奖励
- **目标：** 学习最优策略以获得最大累积奖励
- **算法：** Q学习、深度Q网络（DQN）、策略梯度
- **应用场景：** 游戏AI、机器人控制、资源调度

**比较总结：**
| 方面 | 监督学习 | 无监督学习 | 强化学习 |
|------|----------|------------|----------|
| 数据要求 | 标签数据 | 无标签数据 | 奖励信号 |
| 学习目标 | 映射学习 | 结构发现 | 策略优化 |
| 反馈类型 | 即时正确答案 | 无 | 延迟奖励 |
| 应用领域 | 分类预测 | 聚类降维 | 决策控制 |

**详解：** 三种学习方式解决不同类型的问题，选择合适的学习方式对任务成功至关重要。

## 五、应用题答案

### 1. 图像分类系统设计

**1. 网络架构设计：**

*总体架构：* 卷积神经网络（CNN）
```
输入层 → 卷积层 → 激活函数 → 池化层 → ... → 全连接层 → 输出层
```

*具体设计：*
- **输入层：** 接受224×224×3的RGB图像
- **卷积层1：** 32个3×3卷积核，ReLU激活
- **池化层1：** 2×2最大池化
- **卷积层2：** 64个3×3卷积核，ReLU激活
- **池化层2：** 2×2最大池化
- **卷积层3：** 128个3×3卷积核，ReLU激活
- **池化层3：** 2×2最大池化
- **全连接层1：** 512神经元，Dropout=0.5
- **全连接层2：** 输出类别数神经元
- **输出层：** Softmax激活

**2. 训练过程：**

*前向传播：*
1. 输入图像通过网络逐层计算
2. 得到预测输出
3. 计算损失函数（交叉熵）

*反向传播：*
1. 计算损失对各层参数的梯度
2. 使用优化算法更新参数

*训练循环：*
```python
for epoch in range(num_epochs):
    for batch in train_data:
        # 前向传播
        predictions = forward_pass(batch)
        loss = compute_loss(predictions, true_labels)
        
        # 反向传播
        gradients = backward_pass(loss)
        update_parameters(gradients)
```

**3. 优化策略：**

*数据增强：*
- 随机旋转（±15度）
- 随机翻转
- 颜色抖动
- 随机裁剪

*网络优化：*
- **正则化：** L2正则化、Dropout
- **归一化：** 批归一化
- **优化器：** Adam优化器（学习率自适应）
- **学习率调度：** 余弦退火、阶梯式衰减

*训练策略：*
- 迁移学习：使用预训练模型
- 早停：防止过拟合
- 模型集成：多个模型投票

**4. 评估方法：**

*评估指标：*
- **准确率：** 正确分类的样本比例
- **精确率/召回率：** 针对每个类别的评估
- **F1分数：** 精确率和召回率的调和平均
- **混淆矩阵：** 显示分类结果的详细情况

*评估流程：*
1. 在验证集上评估模型性能
2. 调整超参数
3. 在测试集上进行最终评估
4. 错误分析和模型改进

*交叉验证：* 5折交叉验证确保评估可靠性

**详解：** 图像分类系统需要综合考虑网络架构、训练策略、优化方法和评估指标，通过系统性的设计实现高性能的分类效果。