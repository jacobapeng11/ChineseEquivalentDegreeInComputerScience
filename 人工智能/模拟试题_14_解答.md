# 模拟试题 14 - 详细解答

## 一、选择题解答

1. **答案：A**
   - 解析：状态价值函数V(s)定义为从状态s开始，遵循某个策略的期望累积回报。

2. **答案：C**
   - 解析：感知机只能处理线性可分问题，对于线性不可分数据无法收敛。

3. **答案：D**
   - 解析：独立行动不是一种协调机制，协调需要智能体之间进行交互。

4. **答案：B**
   - 解析：词向量维度通常设置为50-300维，平衡了表达能力和计算效率。

5. **答案：B**
   - 解析：语义网络缺乏标准的推理机制，推理效率较低。

## 二、填空题解答

1. **答案：符号主义（Symbolicism）；连接主义（Connectionism）；行为主义（Actionism）**
   - 解析：AI的三大研究途径。

2. **答案：轮盘赌选择；锦标赛选择；精英保留**
   - 解析：遗传算法中常用的选择方法。

3. **答案：深度神经网络；反向传播算法；计算能力提升**
   - 解析：深度学习的三大技术基础。

4. **答案：正向链式推理；反向链式推理**
   - 解析：专家系统的两种基本推理方式。

5. **答案：句子概率；困惑度（Perplexity）**
   - 解析：语言模型的基本功能和评估指标。

## 三、计算题解答

### 1. 马尔可夫链计算

**题目：** 计算P(X3=s1)

**解答：**
使用马尔可夫性质和全概率公式：
P(X3=s1) = P(X3=s1|X2=s1)P(X2=s1) + P(X3=s1|X2=s2)P(X2=s2)

需要先计算P(X2=s1)和P(X2=s2)：
- P(X2=s1) = P(X2=s1|X1=s1)P(X1=s1) + P(X2=s1|X1=s2)P(X1=s2) = 0.7×0.6 + 0.4×0.4 = 0.42 + 0.16 = 0.58
- P(X2=s2) = P(X2=s2|X1=s1)P(X1=s1) + P(X2=s2|X1=s2)P(X1=s2) = 0.3×0.6 + 0.6×0.4 = 0.18 + 0.24 = 0.42

验证：0.58 + 0.42 = 1 ✓

P(X3=s1) = 0.7×0.58 + 0.4×0.42 = 0.406 + 0.168 = 0.574

**答案：** P(X3=s1) = 0.574

### 2. 神经网络计算

**题目：** 输入x=[1, 0, 1]，线性激活函数

**解答：**
- 隐藏层输入：
  - h1_in = 1×0.2 + 0×0.3 + 1×0.1 + 0.1 = 0.4
  - h2_in = 1×0.4 + 0×0.5 + 1×0.6 + 0.2 = 1.2
- 隐藏层输出（线性激活）：
  - h1_out = 0.4
  - h2_out = 1.2
- 输出层计算：
  - output = 0.4×0.5 + 1.2×0.7 + 0.3 = 0.2 + 0.84 + 0.3 = 1.34

**答案：** 最终输出为1.34

## 四、证明题解答

**题目：** 证明(P → Q) ∧ (Q → R) → (P → R)是重言式

**证明：**
方法1：利用逻辑等价性
- (P → Q) ∧ (Q → R) → (P → R)
- ≡ ¬((P → Q) ∧ (Q → R)) ∨ (P → R)
- ≡ ¬(¬P ∨ Q) ∨ ¬(¬Q ∨ R) ∨ (¬P ∨ R)
- ≡ (P ∧ ¬Q) ∨ (Q ∧ ¬R) ∨ (¬P ∨ R)

分析真值表的关键情况：
当P为真，R为假时，必须Q为真才能使前件为真，此时(Q ∧ ¬R)为真，整个表达式为真。
当P为真，R为真时，整个表达式为真。
当P为假时，(P → R)为真，整个表达式为真。

方法2：直接证明
假设(P → Q) ∧ (Q → R)为真，P为真，需要证明R为真：
- 由P为真和P → Q为真得Q为真
- 由Q为真和Q → R为真得R为真
- 因此P → R为真
- 所以(P → Q) ∧ (Q → R) → (P → R)为重言式

**证毕**

## 五、综合应用题解答

### 深度学习文本情感分析系统

**1. 系统技术架构：**
- **数据输入层：** 接收原始文本数据
- **预处理层：** 分词、去噪、标准化
- **特征提取层：** 词向量表示、上下文编码
- **模型处理层：** 深度学习模型（CNN/RNN/Transformer）
- **分类输出层：** 情感类别预测
- **结果输出层：** 情感标签及置信度

**2. 数据预处理流程：**
- **文本清洗：** 去除HTML标签、特殊字符、URL
- **中文分词：** 使用jieba、pkuseg等工具
- **去停用词：** 移除无意义词汇
- **词干化/词形还原：** 统一词汇形式（中文较少使用）
- **序列化：** 将文本转换为数值序列
- **填充/截断：** 统一输入长度
- **数据增强：** 同义词替换、回译等

**3. 模型选择与设计：**
- **基础模型：** LSTM/GRU捕获序列信息
- **进阶模型：** Transformer/BERT理解上下文
- **集成模型：** CNN提取局部特征 + RNN捕获序列
- **注意力机制：** 关注情感关键词
- **预训练模型：** 使用BERT、RoBerta等预训练模型

**4. 训练与优化策略：**
- **损失函数：** 交叉熵损失
- **优化器：** AdamW，结合权重衰减
- **学习率调度：** warmup + 余弦退火
- **正则化：** Dropout、早停、L2正则化
- **批处理：** 适当的批次大小平衡速度和效果
- **验证策略：** k折交叉验证确保泛化能力

## 六、简答题解答

**搜索算法分类、特点及A*最优性：**

### 搜索算法分类：

**按信息使用：**
- **无信息搜索（盲目搜索）：** BFS、DFS、DLS、IDS、UCS
- **有信息搜索（启发式搜索）：** 贪婪最佳优先、A*、IDA*

**按是否最优：**
- **最优算法：** BFS（最浅解）、UCS（最小代价）、A*
- **非最优算法：** DFS、贪婪最佳优先

**按空间复杂度：**
- **线性空间：** DFS、IDS
- **指数空间：** BFS、A*

### 特点及适用场景：

**BFS：** 完备，最优（单位代价），适合最短路径
**DFS：** 空间效率高，适合深度有限的问题
**UCS：** 找最小代价解
**A*：** 在可采纳启发下最优且高效

### 启发式搜索 vs 无信息搜索：

**相同点：**
- 都是系统性搜索方法
- 都能保证找到解（对完备算法）

**不同点：**
| 方面 | 无信息搜索 | 启发式搜索 |
|------|------------|------------|
| 信息使用 | 仅使用问题定义 | 使用启发信息 |
| 搜索方向 | 盲目扩展 | 根据启发函数指导 |
| 效率 | 较低 | 较高（好的启发） |
| 最优性 | 部分算法保证 | A*等算法保证 |

### A*算法最优性条件：

**1. 可采纳性（Admissibility）：**
- 启发函数h(n)必须不高于从节点n到目标的实际代价h*(n)
- 即对所有节点n，h(n) ≤ h*(n)

**2. 一致性（Consistency）/单调性（Monotonicity）：**
- 对每个节点n和它的后继n'，转移代价c(n, n')
- 满足h(n) ≤ c(n, n') + h(n')
- 一致性 ⇒ 可采纳性

**满足条件时A*性质：**
- **完备性：** 找到解（如果存在）
- **最优性：** 找到最优解
- **最优效率：** 扩展最少节点数